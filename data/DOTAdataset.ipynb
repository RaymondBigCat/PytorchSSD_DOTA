{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "sys.path.append('/home/raymond/project/DOTA_PyTorch/DOTA_devkit') # 保证DOTA_devkit可用的关键\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from DOTA_devkit import dota_utils as util\n",
    "from DOTA_devkit import DOTA\n",
    "# from .voc_eval import voc_eval # VOCdevkit\n",
    "\n",
    "\"\"\"\n",
    "VOC_CLASSES = ('__background__',  # always index 0\n",
    "               'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor')\n",
    "\"\"\"\n",
    "DOTA_CLASSES = ('plane', 'baseball-diamond', 'bridge', 'ground-track-field', 'small-vehicle', 'large-vehicle', 'ship', 'tennis-court',\n",
    "               'basketball-court', 'storage-tank',  'soccer-ball-field', 'roundabout', 'harbor', 'swimming-pool', 'helicopter')\n",
    "\n",
    "class DotaAnnTrans:\n",
    "    \"\"\"Transforms a DOTA annotation into a Tensor of bbox coords and label index\n",
    "    Initilized with a dictionary lookup of classnames to indexes\n",
    "\n",
    "    Arguments:\n",
    "        class_to_ind (dict, optional): dictionary lookup of classnames -> indexes\n",
    "            (default: alphabetic indexing of VOC's 20 classes)\n",
    "        keep_difficult (bool, optional): keep difficult instances or not\n",
    "            (default: False)\n",
    "        height (int): height\n",
    "        width (int): width\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, class_to_ind=None, keep_difficult=True,parseMode = 'parse_dota_rec'):\n",
    "        self.class_to_ind = class_to_ind or dict(\n",
    "            zip(DOTA_CLASSES, range(len(DOTA_CLASSES))))\n",
    "        self.keep_difficult = keep_difficult\n",
    "        self.parseMode = parseMode\n",
    "        if self.parseMode == 'parse_dota_rec':\n",
    "            self.parsekw = 'bndbox'\n",
    "        else:\n",
    "            self.parsekw = 'poly'\n",
    "    def __call__(self, target):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            target (annotation) : the target annotation to be made usable\n",
    "                will be an DOTA.anns\n",
    "        Returns:\n",
    "            a list containing lists of bounding boxes  [bbox coords, class name]\n",
    "        \"\"\"\n",
    "        res = np.empty((0, 5))\n",
    "        '''\n",
    "        在此详细解析label文件\n",
    "        \n",
    "        for obj in target.iter('object'):\n",
    "            difficult = int(obj.find('difficult').text) == 1\n",
    "            if not self.keep_difficult and difficult:\n",
    "                continue\n",
    "            name = obj.find('name').text.lower().strip()\n",
    "            bbox = obj.find('bndbox')\n",
    "\n",
    "            pts = ['xmin', 'ymin', 'xmax', 'ymax']\n",
    "            bndbox = []\n",
    "            # 坐标框append\n",
    "            for i, pt in enumerate(pts):\n",
    "                cur_pt = int(bbox.find(pt).text) - 1\n",
    "                # scale height or width\n",
    "                # cur_pt = cur_pt / width if i % 2 == 0 else cur_pt / height\n",
    "                bndbox.append(cur_pt)\n",
    "        '''\n",
    "        labels = []\n",
    "        # 解析DOTA.loadAnns返回的Anns\n",
    "        if self.parseMode == 'parse_dota_rec':\n",
    "            for num,ann in enumerate(target):\n",
    "                labels.append([])\n",
    "                labels[num].extend(list(ann['bndbox']))\n",
    "                labels[num].append(self.class_to_ind[ann['name']])\n",
    "        # 通过np的vstack进行垂直方向的数组叠加\n",
    "        res = np.vstack((res, labels))  # [xmin, ymin, xmax, ymax, label_ind]\n",
    "        # img_id = target.find('filename').text[:-4]\n",
    "        #\n",
    "        return res  # [[xmin, ymin, xmax, ymax, label_ind], ... ] \n",
    "\n",
    "class DOTADetection(data.Dataset):\n",
    "    \"\"\"DOTA Detection Dataset Object\n",
    "\n",
    "    input is image, target is annotation\n",
    "\n",
    "    Arguments:\n",
    "        rootPath (string): filepath to DOTA dataset folder, will be '/media/raymond/MainDrive/Dataset/DOTA'\n",
    "        \n",
    "        image_set (string): imageset to use (eg. 'train', 'val', 'test', 'train_test')\n",
    "            (default: 'train')\n",
    "            \n",
    "        (None) transform (callable, optional): transformation to perform on the\n",
    "            input image\n",
    "            \n",
    "        preproc : pre-procced of images(eg: data augment) and annotations\n",
    "            (default: None) （在train.py中被调用，preproc类在data_augment.py里）\n",
    "            \n",
    "        target_transform (callable, optional): transformation to perform on the\n",
    "            target `annotation`\n",
    "            (eg: take in caption string, return tensor of word indices)\n",
    "            \n",
    "        dataset_name (string, optional): which dataset to load\n",
    "            (default: 'DOTA')\n",
    "            \n",
    "        parseMode: choose the format for parsing the annotation\n",
    "            (default:'parse_dota_rec', which anns will be parsed as [xmin, ymin, xmax, ymax] \n",
    "            \n",
    "        catNms: choose the category of obejcts that will be loaded\n",
    "            (default: [] , means all)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rootPath, image_sets='train', preproc=None, target_transform=None,\n",
    "                 dataset_name='DOTA', parseMode='parse_dota_rec', catNms=[]):\n",
    "        self.rootPath = rootPath\n",
    "        self.image_set = image_sets\n",
    "        # 构造DOTA加载路径\n",
    "        self.path = os.path.join(self.rootPath, self.image_set)\n",
    "        # 预处理，默认None\n",
    "        self.preproc = preproc\n",
    "        # target_transform = AnnotationTransform\n",
    "        self.target_transform = target_transform\n",
    "        self.name = dataset_name\n",
    "        # 解析方式\n",
    "        self.parseMode = parseMode\n",
    "        # DOTA筛选类别\n",
    "        self.catNms = catNms\n",
    "        # 加载DOTA(imgIDs, anns)\n",
    "        self.dataset = DOTA.DOTA(self.path, parseMode=self.parseMode)\n",
    "        self.imgIDs = self.dataset.getImgIds(self.catNms)\n",
    "        # 将类别编码为数字\n",
    "        # self.class_to_ind = dict(zip(DOTA_CLASSES,range(len(DOTA_CLASSES))))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.imgIDs[index]\n",
    "        # 调用DOTA devkit 的方法load imgs（背后是cv2的imread）\n",
    "        img = self.dataset.loadImgs(img_id)[0]\n",
    "        target = self.dataset.loadAnns(imgId=img_id)\n",
    "        # target 即是 Label\n",
    "        # \n",
    "        # img = cv2.imread(self._imgpath % img_id, cv2.IMREAD_COLOR)\n",
    "        # height, width, _ = img.shape\n",
    "        \n",
    "        '''\n",
    "        详细解析Anns'''\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)  \n",
    "        '''\n",
    "        数据增强，resize图像等一系列操作都在data_augment的preproc里面'''\n",
    "        if self.preproc is not None:\n",
    "            # preproc \n",
    "            img, target = self.preproc(img, target)\n",
    "            # print(img.size())\n",
    "\n",
    "            # target = self.target_transform(target, width, height)\n",
    "        # print(target.shape)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DOTA dataset has been successfully loaded \n",
      "加载图片ID完成：返回所有图片ID\n",
      "10\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/raymond/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/raymond/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 135, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/raymond/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 135, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/raymond/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 121, in default_collate\n    return torch.stack([torch.from_numpy(b) for b in batch], 0)\n  File \"/home/raymond/anaconda3/lib/python3.6/site-packages/torch/functional.py\", line 64, in stack\n    return torch.cat(inputs, dim)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 5502 and 5774 in dimension 1 at /pytorch/torch/lib/TH/generic/THTensorMath.c:2897\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0afa9f32d614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mepoch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdota_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Traceback (most recent call last):\n  File \"/home/raymond/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/raymond/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 135, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/raymond/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 135, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/raymond/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 121, in default_collate\n    return torch.stack([torch.from_numpy(b) for b in batch], 0)\n  File \"/home/raymond/anaconda3/lib/python3.6/site-packages/torch/functional.py\", line 64, in stack\n    return torch.cat(inputs, dim)\nRuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 5502 and 5774 in dimension 1 at /pytorch/torch/lib/TH/generic/THTensorMath.c:2897\n"
     ]
    }
   ],
   "source": [
    "# from data_augment import preproc\n",
    "root = '/media/raymond/MainDrive/Dataset/DOTA'\n",
    "img_dim = 512\n",
    "rgb_means = (104,117,123)\n",
    "rgb_std = (1,1,1)\n",
    "p = 0.6\n",
    "dota_test = DOTADetection(root,\n",
    "                          image_sets='train_test',\n",
    "                          # preproc=(img_dim, rgb_means, rgb_std, p),\n",
    "                          target_transform=DotaAnnTrans()\n",
    "                         )\n",
    "dota_dataloader = data.DataLoader(dota_test,\n",
    "                                  batch_size=4,\n",
    "                                  shuffle=False,\n",
    "                                  num_workers=2,\n",
    "                                  pin_memory=True)\n",
    "dataiter = data.dataloader.DataLoaderIter(dota_dataloader)\n",
    "epoch_size = len(dota_test)\n",
    "print(epoch_size)\n",
    "print(next(dataiter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
